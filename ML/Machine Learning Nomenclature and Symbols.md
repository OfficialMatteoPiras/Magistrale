| Symbol                      | Name or Concept                           | Description                                                                                                                                                                                               |
| --------------------------- | ----------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ML                          | Machine Learning                          | Provides an extremely useful framework and set of tools to tackle decisions based on limited information provided by measured data. It involves creating a model to predict what comes next using tokens. |
| x                           | Input                                     | A vector of values (x∈X(=Rd)) from which a prediction is desired.                                                                                                                                         |
| y                           | Output                                    | The value to predict (y∈Y).                                                                                                                                                                               |
| f                           | Target Function                           | The formula that the model would ideally like to learn (f:X→Y).                                                                                                                                           |
| h                           | Hypothesis                                | The formula that is used (h:X→Y).                                                                                                                                                                         |
| H                           | Model Classes / Hypothesis Set            | The set of possible hypotheses (h∈H).                                                                                                                                                                     |
| S                           | Training Set / Sample Set                 | The set of training data points: S={zi​=(xi​,yi​)}i=1,…,n​.                                                                                                                                               |
| z                           | Data Point                                | A couple (input, output), z=(x,y).                                                                                                                                                                        |
| D                           | Distribution                              | The way to generate data.                                                                                                                                                                                 |
| Dx​                         | Input Distribution                        | The distribution of the input (x∼Dx​).                                                                                                                                                                    |
| $D_{yx}$                    | Output Distribution                       | Conditional Output Distribution                                                                                                                                                                           |
| A                           | Learning Algorithm                        | The process that, given the training examples S, produces a final hypothesis h^S​.                                                                                                                        |
| h^ / h^S​                   | Final Hypothesis / Estimate of h          | The "learned" function that should perform well on future unseen data.                                                                                                                                    |
| l(h,z)                      | Loss (Error) Function                     | Measures how good the function h is at describing the data point z=(x,y), with l(h,z)≥0.                                                                                                                  |
| 0-1 Loss                    | Zero-One Loss                             | A common loss function for binary classification (Y={0,1}).                                                                                                                                               |
| LS​(h)                      | Empirical Loss (Risk)                     | The training error, which is the average loss over the training set S.                                                                                                                                    |
| ERM                         | Empirical Risk Minimization               | The algorithm that finds the hypothesis that minimizes the empirical risk: h^S​∈argminh∈H​Ls​(h).                                                                                                         |
| LD​(h)                      | True Risk                                 | The generalization error. It is equal to the probability that h incorrectly classifies z.                                                                                                                 |
| h∗                          | Optimal Hypothesis (Realizable Case)      | An hypothesis in H such that the True Risk is zero, LD​(h∗)=0.                                                                                                                                            |
| Realizability Assumption    | Realizability                             | A model class H satisfies this if ∃h∗∈H s.t. LD​(h∗)=0.                                                                                                                                                   |
| PAC-Learning                | Probably Approximately Correct Learning   | A theoretical framework where P[LD​(h^S​)≤ϵ]≥1−δ.                                                                                                                                                         |
| ϵ                           | Accuracy Parameter                        | Parameter related to the maximum allowed error on the True Risk.                                                                                                                                          |
| δ                           | Confidence Parameter                      | Parameter related to the probability of the error being greater than ϵ (P[LD​(h^S​)>ϵ]<δ).                                                                                                                |
| m                           | Sample Size / Number of Training Examples | The size of the training set S (n or m).                                                                                                                                                                  |
| mH​(ϵ,δ)                    | Sample Complexity of H                    | The minimum sample size required for PAC-Learning: $m*=\frac{1}{\epsilon}log(\frac{                                                                                                                       |
| Agnostic PAC-Learning       | Agnostic PAC-Learning                     | What happens when minh∈H​LD​(H)>0 (i.e., realizability does not hold). The goal is LD​(h^S​)<minh∈H​LD​(h)+ϵ.                                                                                             |
| ϵ-representative sample     | ϵ-representative sample                   | A sample S such that $                                                                                                                                                                                    |
| Supervised Learning         | Supervised Learning                       | Learning where yi​'s are known. Includes classification and regression.                                                                                                                                   |
| Unsupervised Learning       | Unsupervised Learning                     | Learning where yi​'s are not known. Includes clustering and dimensionality reduction.                                                                                                                     |
| Reinforcement Learning (RL) | Reinforcement Learning                    | On-line optimal data-driven control, involving an AGENT learning to optimize CUMULATIVE REWARD in an ENVIRONMENT.                                                                                         |
